{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from scipy.special import softmax\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPE(y_true, y_pred):\n",
    "    # computes the MAPE\n",
    "    return np.mean(np.abs(y_true - y_pred) / y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits = pd.read_parquet('train_visits.parquet.gzip')\n",
    "ports = pd.read_parquet('ports_prep.parquet.gzip')\n",
    "vessels = pd.read_parquet('vessels_prep.parquet.gzip')\n",
    "\n",
    "ports = ports.set_index('port_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the dataframe\n",
    "- Select the instances where a target is present\n",
    "- Sort values for the split\n",
    "- Drop irrelevant columns\n",
    "- Add an identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = visits[visits['target_travel_duration'].notnull()]\n",
    "df = df.sort_values('entry_datetime')\n",
    "\n",
    "df = df.drop(['entry_datetime', 'target_entry_datetime', \n",
    "                      'exit_datetime', 'previous_exit_datetime',\n",
    "                      'target_stay_duration', 'previous_portname', \n",
    "                      'previous_entry_datetime', 'prev2_exit_datetime'], 1)\n",
    "\n",
    "\n",
    "df['identifier'] = df['mmsi'].astype(str) + '_' + df.groupby('mmsi').cumcount().astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Features\n",
    "- Add the same features as in port prediction/stay duration\n",
    "- Uses pivots for more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pivots(port_only=False):\n",
    "    #add iso3 codes to hist_visits\n",
    "    ports=pd.read_parquet('ports_prep.parquet.gzip').set_index('port_index')\n",
    "    hist_visits = pd.read_parquet('hist_visits.parquet.gzip')\n",
    "    hist_visits = pd.merge(hist_visits, ports[['iso3']].reset_index(), how='left', on='port_index')\n",
    "    hist_visits = pd.merge(hist_visits, ports[['iso3']].rename(columns={'iso3':'target_iso3'}), \n",
    "                               how='left', left_on='target_port_index', right_index=True)\n",
    "    \n",
    "    hist_visits['hist_connections'] = 1\n",
    "    \n",
    "    #Connections between ports\n",
    "    port_pt = pd.pivot_table(hist_visits, index=['port_index', 'target_port_index'], \n",
    "                        values='hist_connections', aggfunc='count').fillna(0).reset_index()\n",
    "    port_pt.rename(columns={'hist_connections': 'port_hist_connections'}, inplace=True)\n",
    "    port_pt = port_pt.set_index(['port_index', 'target_port_index'])\n",
    "    \n",
    "    if port_only:\n",
    "        return port_pt\n",
    "    \n",
    "    #travel time/stay duration between ports\n",
    "    port_pt2 = pd.pivot_table(hist_visits, index=['port_index', 'target_port_index'], \n",
    "                        values=['target_travel_duration', 'target_stay_duration'], \n",
    "                         aggfunc=['mean', 'std', 'max', 'min']).reset_index()\n",
    "    port_pt2 = port_pt2.set_index(['port_index', 'target_port_index'])\n",
    "    port_pt2.columns = ['ports_' + '_'.join((str(j), str(k))) for j, k in port_pt2.columns]  \n",
    "    \n",
    "    \n",
    "    #connections between countries\n",
    "    iso_pt = pd.pivot_table(hist_visits, index=['iso3', 'target_iso3'], \n",
    "                        values='hist_connections', aggfunc='count').fillna(0).reset_index()\n",
    "    iso_pt.rename(columns={'hist_connections': 'iso_hist_connections'}, inplace=True)\n",
    "    iso_pt = iso_pt.set_index(['iso3', 'target_iso3'])\n",
    "\n",
    "    #travel time/stay duration between countries\n",
    "    iso_pt2 = pd.pivot_table(hist_visits, index=['iso3', 'target_iso3'], \n",
    "                        values=['target_travel_duration', 'target_stay_duration'], \n",
    "                         aggfunc=['mean', 'std', 'max', 'min']).reset_index()\n",
    "    iso_pt2 = iso_pt2.set_index(['iso3', 'target_iso3'])\n",
    "    iso_pt2.columns = ['iso3_' + '_'.join((str(j), str(k))) for j, k in iso_pt2.columns]    \n",
    "    \n",
    "\n",
    "    #merge datasets\n",
    "    port_pt = pd.merge(port_pt, port_pt2, left_index=True, right_index=True)\n",
    "    iso_pt = pd.merge(iso_pt, iso_pt2, left_index=True, right_index=True)\n",
    "\n",
    "    \n",
    "    #previous port --> target port connections\n",
    "    prev_pt = pd.pivot_table(hist_visits, index=['previous_port_index', 'target_port_index'], \n",
    "                        values='hist_connections', aggfunc='count').fillna(0).reset_index()\n",
    "    prev_pt.rename(columns={'hist_connections': 'prev_hist_connections'}, inplace=True)\n",
    "    prev_pt = prev_pt.set_index(['previous_port_index', 'target_port_index'])\n",
    "    \n",
    "    #prev2 port --> target port connections\n",
    "    prev2_pt = pd.pivot_table(hist_visits, index=['prev2_port_index', 'target_port_index'], \n",
    "                            values='hist_connections', aggfunc='count').fillna(0).reset_index()\n",
    "    prev2_pt.rename(columns={'hist_connections': 'prev2_hist_connections'}, inplace=True)\n",
    "    prev2_pt = prev2_pt.set_index(['prev2_port_index', 'target_port_index'])\n",
    "    \n",
    "    return port_pt, iso_pt, prev_pt, prev2_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(dataset):\n",
    "    port_pt, iso_pt, prev_pt, prev2_pt = get_pivots()\n",
    "    ports = pd.read_parquet('ports_prep.parquet.gzip').set_index('port_index')\n",
    "    distances = pd.read_excel('CERDI.xlsx').set_index(['iso1', 'iso2'])[['seadistance']]\n",
    "    og_port_columns = ports.columns\n",
    "    \n",
    "    #add target port features\n",
    "    ports.columns = ['target_' + column for column in og_port_columns]\n",
    "    dataset = pd.merge(dataset, ports, how='left', left_on='target_port_index', right_index=True)\n",
    "    ports.columns = og_port_columns\n",
    "    \n",
    "    #add port_pt, iso_pt features\n",
    "    dataset = pd.merge(dataset, port_pt, how='left', left_on=['port_index', 'target_port_index'], right_index=True)\n",
    "    dataset = pd.merge(dataset, iso_pt, how='left', left_on=['iso3', 'target_iso3'], right_index=True)\n",
    "    dataset['port_hist_connections'] = dataset['port_hist_connections'].fillna(0)\n",
    "    dataset['iso_hist_connections'] = dataset['iso_hist_connections'].fillna(0)\n",
    "    \n",
    "    #add fav port connections\n",
    "    port_pt = port_pt.reset_index().groupby('port_index').head(1)\n",
    "    dataset = pd.merge(dataset, port_pt[['port_index', 'target_port_index', \n",
    "                       'port_hist_connections']].rename(columns={'target_port_index': 'port_fav_port',\n",
    "                       'port_hist_connections': 'port_fav_port_count'}), \n",
    "                       how='left', on='port_index')\n",
    "    dataset['port_fav_port_count'] = dataset['port_fav_port_count'].fillna(0)\n",
    "    dataset['port_fav_port'] = dataset['port_fav_port'].astype('object').fillna('Unknown').astype('category')\n",
    "\n",
    "    ports.columns = ['port_fav_' + column for column in og_port_columns]\n",
    "    dataset = pd.merge(dataset, ports[['port_fav_port_lat', 'port_fav_port_long']], \n",
    "                       how='left', left_on='target_port_index', right_index=True)\n",
    "    ports.columns = og_port_columns\n",
    "    \n",
    "    #add previous and prev2 pt features\n",
    "    dataset = pd.merge(dataset, prev_pt, how='left', left_on=['previous_port_index', 'target_port_index'], right_index=True)\n",
    "    dataset = pd.merge(dataset, prev2_pt, how='left', left_on=['prev2_port_index', 'target_port_index'], right_index=True)\n",
    "    dataset['prev_hist_connections'] = dataset['prev_hist_connections'].fillna(0)\n",
    "    dataset['prev2_hist_connections'] = dataset['prev2_hist_connections'].fillna(0)    \n",
    "    \n",
    "    #add seadistance curr -- target\n",
    "    dataset = pd.merge(dataset, distances[['seadistance']], how='left',\n",
    "                       left_on=['iso3', 'target_iso3'], right_index=True)\n",
    "    dataset['seadistance'] = dataset['seadistance'].fillna(0)\n",
    "\n",
    "    #add seadistance prev -- target\n",
    "    dataset = pd.merge(dataset, distances[['seadistance']].rename(columns={'seadistance': 'prev_tar_seadistance'}), \n",
    "                       how='left', left_on=['previous_iso3', 'target_iso3'], right_index=True)\n",
    "    dataset['prev_tar_seadistance'] = dataset['prev_tar_seadistance'].fillna(0)\n",
    "\n",
    "    #add seadistance prev2 -- target\n",
    "    dataset = pd.merge(dataset, distances[['seadistance']].rename(columns={'seadistance': 'prev2_tar_seadistance'}), \n",
    "                       how='left', left_on=['prev2_iso3', 'target_iso3'], right_index=True)\n",
    "    dataset['prev2_tar_seadistance'] = dataset['prev2_tar_seadistance'].fillna(0)\n",
    "    \n",
    "    #add euclidean distances\n",
    "    dataset['eucl_cur_tar'] = np.sqrt((dataset['port_lat'] - dataset['target_port_lat'])**2 + \n",
    "                                 (dataset['port_long'] - dataset['target_port_long'])**2)\n",
    "    dataset['eucl_cur_prev'] = np.sqrt((dataset['port_lat'] - dataset['previous_port_lat'])**2 + \n",
    "                                 (dataset['port_long'] - dataset['previous_port_long'])**2)\n",
    "    dataset['eucl_tar_prev'] = np.sqrt((dataset['target_port_lat'] - dataset['previous_port_lat'])**2 + \n",
    "                                 (dataset['target_port_long'] - dataset['previous_port_long'])**2)\n",
    "    dataset['eucl_ves_tar'] = np.sqrt((dataset['mean_port_lat'] - dataset['target_port_lat'])**2 + \n",
    "                                 (dataset['mean_port_long'] - dataset['target_port_long'])**2)\n",
    "    dataset['eucl_ves_cur'] = np.sqrt((dataset['mean_port_lat'] - dataset['port_lat'])**2 + \n",
    "                                 (dataset['mean_port_long'] - dataset['port_long'])**2)\n",
    "    dataset['eucl_ves_prev'] = np.sqrt((dataset['mean_port_lat'] - dataset['previous_port_lat'])**2 + \n",
    "                                 (dataset['mean_port_long'] - dataset['previous_port_long'])**2)\n",
    "    \n",
    "    dataset['eucl_cur_prev2'] = np.sqrt((dataset['port_lat'] - dataset['prev2_port_lat'])**2 + \n",
    "                                 (dataset['port_long'] - dataset['prev2_port_long'])**2)\n",
    "    dataset['eucl_tar_prev2'] = np.sqrt((dataset['target_port_lat'] - dataset['prev2_port_lat'])**2 + \n",
    "                                 (dataset['target_port_long'] - dataset['prev2_port_long'])**2)\n",
    "    dataset['eucl_prev_prev2'] = np.sqrt((dataset['previous_port_lat'] - dataset['prev2_port_lat'])**2 + \n",
    "                                 (dataset['previous_port_long'] - dataset['prev2_port_long'])**2)\n",
    "    dataset['eucl_ves_prev2'] = np.sqrt((dataset['mean_port_lat'] - dataset['prev2_port_lat'])**2 + \n",
    "                                 (dataset['mean_port_long'] - dataset['prev2_port_long'])**2)    \n",
    "\n",
    "    dataset['eucl_ves_fav_cur'] = np.sqrt((dataset['vessel_fav_port_lat'] - dataset['port_lat'])**2 + \n",
    "                                 (dataset['vessel_fav_port_long'] - dataset['port_long'])**2)\n",
    "    dataset['eucl_ves_fav_tar'] = np.sqrt((dataset['vessel_fav_port_lat'] - dataset['target_port_lat'])**2 + \n",
    "                                 (dataset['vessel_fav_port_long'] - dataset['target_port_long'])**2)\n",
    "    dataset['eucl_ves_fav_prev'] = np.sqrt((dataset['vessel_fav_port_lat'] - dataset['previous_port_lat'])**2 + \n",
    "                                 (dataset['vessel_fav_port_long'] - dataset['previous_port_long'])**2)\n",
    "    dataset['eucl_ves_fav_prev2'] = np.sqrt((dataset['vessel_fav_port_lat'] - dataset['prev2_port_lat'])**2 + \n",
    "                                 (dataset['vessel_fav_port_long'] - dataset['prev2_port_long'])**2) \n",
    "    dataset['eucl_ves_fav_ves'] = np.sqrt((dataset['vessel_fav_port_lat'] - dataset['mean_port_lat'])**2 + \n",
    "                                 (dataset['vessel_fav_port_long'] - dataset['mean_port_long'])**2)\n",
    "    \n",
    "    dataset['eucl_port_fav_tar'] = np.sqrt((dataset['port_fav_port_lat'] - dataset['target_port_lat'])**2 + \n",
    "                                 (dataset['port_fav_port_long'] - dataset['target_port_long'])**2)\n",
    "    dataset['eucl_port_fav_prev'] = np.sqrt((dataset['port_fav_port_lat'] - dataset['previous_port_lat'])**2 + \n",
    "                                 (dataset['port_fav_port_long'] - dataset['previous_port_long'])**2)\n",
    "    dataset['eucl_port_fav_ves'] = np.sqrt((dataset['port_fav_port_lat'] - dataset['mean_port_lat'])**2 + \n",
    "                                 (dataset['port_fav_port_long'] - dataset['mean_port_long'])**2)    \n",
    "    dataset['eucl_port_fav_ves_fav'] = np.sqrt((dataset['port_fav_port_lat'] - dataset['vessel_fav_port_lat'])**2 + \n",
    "                                 (dataset['port_fav_port_long'] - dataset['vessel_fav_port_long'])**2)   \n",
    "    \n",
    "    #add rankings\n",
    "    dataset['rank_port_connections'] = dataset.groupby('identifier')['port_hist_connections'].rank(axis=0, \n",
    "                                                                                        method='min', ascending=False)\n",
    "    dataset['rank_iso_connections'] = dataset.groupby('identifier')['iso_hist_connections'].rank(axis=0, \n",
    "                                                                                        method='min', ascending=False)\n",
    "    dataset['rank_prev_connections'] = dataset.groupby('identifier')['prev_hist_connections'].rank(axis=0, \n",
    "                                                                                        method='min', ascending=False)\n",
    "    dataset['rank_prev2_connections'] = dataset.groupby('identifier')['prev2_hist_connections'].rank(axis=0, \n",
    "                                                                                        method='min', ascending=False)\n",
    "    dataset['rank_seadistance'] = dataset.groupby('identifier')['seadistance'].rank(axis=0, method='min')\n",
    "    dataset['rank_prev_tar_seadistance'] = dataset.groupby('identifier')['prev_tar_seadistance'].rank(axis=0, method='min')\n",
    "    dataset['rank_eucl_cur_tar'] = dataset.groupby('identifier')['eucl_cur_tar'].rank(axis=0, method='min')\n",
    "    dataset['rank_eucl_tar_prev'] = dataset.groupby('identifier')['eucl_tar_prev'].rank(axis=0, method='min')\n",
    "    dataset['rank_eucl_tar_ves_fav'] = dataset.groupby('identifier')['eucl_ves_fav_tar'].rank(axis=0, method='min')\n",
    "    dataset['rank_eucl_tar_mean'] = dataset.groupby('identifier')['eucl_ves_tar'].rank(axis=0, method='min')\n",
    "    dataset['rank_eucl_port_fav_tar'] = dataset.groupby('identifier')['eucl_port_fav_tar'].rank(axis=0, method='min')\n",
    "    \n",
    "    #rename a column\n",
    "    dataset.rename(columns={'n_visits_y': 'n_visits'}, inplace=True)\n",
    "    \n",
    "    #add some difference metrics\n",
    "    for col in ['port_lat', 'port_long', 'n_visits', 'n_unique_vessels',\n",
    "           'n_high_speed', 'n_medium_speed', 'n_Chemical/Oil Tanker', 'n_Container Ship', 'n_Crude Oil Tanker',\n",
    "           'n_General Cargo Ship', 'n_Tanker', 'n_large_length', 'n_medium_length',\n",
    "           'n_small_length', 'n_very large_length', 'n_large_depth',\n",
    "           'n_medium_depth', 'n_small_depth', 'n_very large_depth', 'port_avg_distance_to_port', 'port_avg_travel_duration',\n",
    "           'port_avg_stay_duration' ]:\n",
    "        dataset[f'prev_curr_diff_{col}'] = abs(dataset[col] - dataset[f'previous_{col}'])\n",
    "        dataset[f'curr_targ_diff_{col}'] = abs(dataset[f'target_{col}'] - dataset[col])\n",
    "        dataset[f'fav_targ_diff_{col}'] = abs(dataset[f'target_{col}'] - dataset[f'vessel_fav_{col}'])   \n",
    "    \n",
    "    \n",
    "    dataset['prev_speed_coor'] = (dataset['eucl_cur_prev']*111) / np.exp(dataset['previous_travel_duration'])\n",
    "    dataset['prev_speed_sead'] = dataset['previous_seadistance'] / np.exp(dataset['previous_travel_duration'])\n",
    "    dataset['prev2_speed_coor'] = (dataset['eucl_prev_prev2']*111) / np.exp(dataset['prev2_travel_duration'])\n",
    "    dataset['prev2_speed_sead'] = dataset['prev2_prev_seadistance'] / np.exp(dataset['prev2_travel_duration'])\n",
    "    \n",
    "    dataset['exp_trav_prev_coor'] = np.log((dataset['eucl_cur_tar']*111) / dataset['prev_speed_coor'])\n",
    "    dataset['exp_trav_prev_sead'] = np.log(dataset['seadistance'] / dataset['prev_speed_sead'])\n",
    "    dataset['exp_trav_prev2_coor'] = np.log((dataset['eucl_cur_tar']*111) / dataset['prev2_speed_coor'])\n",
    "    dataset['exp_trav_prev2_sead'] = np.log(dataset['seadistance'] / dataset['prev2_speed_sead'])\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = add_features(df)\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping\n",
    "- Use the same mapping as the one from port predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = pickle.load(open('mappings.p', 'rb'))\n",
    "\n",
    "for column in dataset.columns[dataset.dtypes == 'object']:\n",
    "    if (column != 'identifier') and ('iso3' not in column) and ('portname' not in column):\n",
    "        print(column)\n",
    "        dataset[column] = dataset[column].map(mappings[column]).astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN TEST SPLIT\n",
    "- Split the data on time\n",
    "- There are some columns we do not want to use in the model. For example using the mmsi prohibits the model to be effective for unseen vessels. Also the features with many categories (such as mmsi) could induce overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.set_index(['identifier', 'port_index', 'target_port_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.index.levels[0].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cutoff = int(len(dataset)*0.6)\n",
    "val_cutoff = int(len(dataset)*0.8)\n",
    "\n",
    "traindf = dataset.iloc[:train_cutoff]\n",
    "valdf = dataset.iloc[train_cutoff:val_cutoff]\n",
    "testdf = dataset.iloc[val_cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_not_train = ['portname', 'target_portname', 'prev2_portname',\n",
    "                 'mmsi_iso3', 'iso3', 'previous_iso3', 'prev2_iso3', 'target_iso3',\n",
    "                 'prev2_port_index', 'vessel_fav_portname', 'vessel_fav_iso3', 'vessel_fav_port_index',\n",
    "                 'port_fav_port', 'target_travel_duration']\n",
    "\n",
    "cols_train = traindf.drop(cols_not_train, 1).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE SELECTION\n",
    "- Define a model\n",
    "- Fit a model\n",
    "- Select the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMRegressor(max_depth=10, n_estimators=500, learning_rate=.05, verbose=1,\n",
    "                   min_child_samples=5000, num_leaves=25, metric=['rmse', 'mape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(traindf[cols_train], traindf['target_travel_duration'].values, \n",
    "         eval_set=[(traindf[cols_train], traindf['target_travel_duration'].values), \n",
    "                   (valdf[cols_train], valdf['target_travel_duration'].values)],\n",
    "         eval_metric=['rmse', 'mape'],\n",
    "         verbose=10, early_stopping_rounds=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Feature': cols_train, 'Importance': model.feature_importances_}).sort_values('Importance').tail(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = pd.DataFrame({'Feature': cols_train, \n",
    "                         'Importance': model.feature_importances_}).sort_values('Importance').tail(50)['Feature'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL\n",
    "- Define a model\n",
    "- Train a model on the selected features\n",
    "- Check performance\n",
    "- Save the used features and the model\n",
    "- Save the predictions to be analyzed in the results notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMRegressor(max_depth=15, n_estimators=5000, learning_rate=.025, verbose=1,\n",
    "                   min_child_samples=500, num_leaves=50, metric=['mape', 'rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(traindf[new_cols], traindf['target_travel_duration'].values, \n",
    "         eval_set=[(traindf[new_cols], traindf['target_travel_duration'].values), \n",
    "                   (valdf[new_cols], valdf['target_travel_duration'].values)],\n",
    "         eval_metric=['mape', 'rmse'],\n",
    "         verbose=10, early_stopping_rounds=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "lgb.plot_metric(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(testdf[new_cols])\n",
    "\n",
    "print ('MAPE (test):', MAPE(np.exp(testdf['target_travel_duration']), np.exp(prediction)))\n",
    "print ('RMSE (test):', np.sqrt(mse(np.exp(testdf['target_travel_duration']), np.exp(prediction))))\n",
    "print()\n",
    "\n",
    "print(np.corrcoef(np.exp(testdf['target_travel_duration']), np.exp(prediction)))\n",
    "print()\n",
    "\n",
    "plt.plot(np.exp(testdf['target_travel_duration']), np.exp(prediction), 'o', markersize=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Feature': new_cols, 'Importance': model.feature_importances_}).sort_values('Importance').tail(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(new_cols, open('travel_cols.p', 'wb'))\n",
    "pickle.dump(model, open('travel_model.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = testdf[['port_lat', 'port_long', 'target_port_lat', \n",
    "                  'target_port_long', 'eucl_cur_tar', 'target_travel_duration']].reset_index()\n",
    "results['prediction'] = np.exp(prediction)\n",
    "results['target_travel_duration'] = np.exp(results['target_travel_duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('travel_prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "- Baseline uses the historic visits as well as the train dataset\n",
    "- Computes the average travel duration between ports\n",
    "- Save the predictions to evaluate them in the Results notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_visits = pd.read_parquet('hist_visits.parquet.gzip')\n",
    "hist_visits = hist_visits[['port_index', 'target_port_index', 'target_travel_duration']]\n",
    "hist_visits = pd.concat([hist_visits, traindf[['target_travel_duration']].reset_index()])\n",
    "hist_visits = hist_visits.drop('identifier', 1)\n",
    "\n",
    "print(hist_visits.shape)\n",
    "hist_visits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = pd.pivot_table(hist_visits, index=['port_index', 'target_port_index'], \n",
    "                    values='target_travel_duration', aggfunc='mean').reset_index()\n",
    "\n",
    "print(pt.shape)\n",
    "pt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testbase = pd.merge(testdf[['port_lat', 'port_long', 'target_port_lat', \n",
    "                  'target_port_long', 'eucl_cur_tar', 'target_travel_duration']].reset_index(), \n",
    "                    pt[['port_index', 'target_port_index', \n",
    "                        'target_travel_duration']].rename(columns={'target_travel_duration':'prediction'}),\n",
    "                    how='left', on=['port_index', 'target_port_index'])\n",
    "\n",
    "testbase['prediction'] = testbase['prediction'].fillna(testbase['prediction'].mean())\n",
    "\n",
    "print(testbase.shape)\n",
    "testbase.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('MAPE (test):', MAPE(np.exp(testbase['target_travel_duration']), np.exp(testbase['prediction'])))\n",
    "print ('RMSE (test):', np.sqrt(mse(np.exp(testbase['target_travel_duration']), np.exp(testbase['prediction']))))\n",
    "print()\n",
    "\n",
    "print(np.corrcoef(np.exp(testbase['target_travel_duration']), np.exp(testbase['prediction'])))\n",
    "print()\n",
    "\n",
    "plt.plot(np.exp(testbase['target_travel_duration']), np.exp(testbase['prediction']), 'o', markersize=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testbase.to_csv('BASELINE_travel_prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
